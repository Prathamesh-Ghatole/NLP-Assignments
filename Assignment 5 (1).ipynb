{"cells":[{"cell_type":"markdown","id":"b7145ae9","metadata":{"id":"b7145ae9"},"source":["\n","# Assignment 5"]},{"cell_type":"markdown","id":"8c67b5f7","metadata":{"id":"8c67b5f7"},"source":["Implement a code for aspect mining and topic modeling"]},{"cell_type":"markdown","id":"3af2f17e","metadata":{"id":"3af2f17e"},"source":["# Topic Modeling"]},{"cell_type":"code","execution_count":null,"id":"07b4dc36","metadata":{"id":"07b4dc36"},"outputs":[],"source":["doc1 = \"She loves to write short stories in the local coffee shop.\"\n","doc2 = \"My Bill spends a lot of time driving my sister around to dance practice.\"\n","doc3 = \"Doctors suggest that driving may cause increased stress and blood pressure.\"\n","doc4 = \"Nisha and her friends danced happily.\"\n","doc5 = \"She won't be attending the Met Gala this year.\"\n","\n","doc_complete = [doc1, doc2, doc3, doc4, doc5]"]},{"cell_type":"code","execution_count":null,"id":"04beae0b","metadata":{"id":"04beae0b","outputId":"541325ea-046d-4f3d-a638-204aee3b55fb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: nltk in c:\\users\\prati\\anaconda3\\lib\\site-packages (3.7)Note: you may need to restart the kernel to use updated packages.\n","Requirement already satisfied: tqdm in c:\\users\\prati\\anaconda3\\lib\\site-packages (from nltk) (4.64.0)\n","\n","Requirement already satisfied: click in c:\\users\\prati\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n","Requirement already satisfied: joblib in c:\\users\\prati\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n","Requirement already satisfied: regex>=2021.8.3 in c:\\users\\prati\\anaconda3\\lib\\site-packages (from nltk) (2022.3.15)\n","Requirement already satisfied: colorama in c:\\users\\prati\\appdata\\roaming\\python\\python39\\site-packages (from click->nltk) (0.4.4)\n"]}],"source":["pip install nltk"]},{"cell_type":"code","execution_count":null,"id":"c68957dc","metadata":{"id":"c68957dc"},"outputs":[],"source":["from nltk.corpus import stopwords\n","from nltk.stem.wordnet import WordNetLemmatizer\n","import string\n","stop = set(stopwords.words('english'))\n","exclude = set(string.punctuation)\n","lemma = WordNetLemmatizer()\n","\n","def clean(doc):\n","    stop_free = ' '.join([i for i in doc.lower().split() if i not in stop])\n","    punc_free = ''.join([ch for ch in stop_free if ch not in exclude])\n","    normalized = ' '.join(lemma.lemmatize(word) for word in punc_free.split())\n","    return normalized\n","doc_clean = [clean(doc).split() for doc in doc_complete]"]},{"cell_type":"code","execution_count":null,"id":"fb814719","metadata":{"id":"fb814719"},"outputs":[],"source":["import gensim\n","from gensim import corpora\n","dictionary = corpora.Dictionary(doc_clean)\n","doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]"]},{"cell_type":"code","execution_count":null,"id":"72a19d15","metadata":{"id":"72a19d15"},"outputs":[],"source":["Lda = gensim.models.ldamodel.LdaModel\n","ldamodel = Lda(doc_term_matrix, num_topics = 3, id2word = dictionary, passes=50)"]},{"cell_type":"code","execution_count":null,"id":"f5c7a64f","metadata":{"id":"f5c7a64f","outputId":"5c4e452e-f67e-468c-ecfa-8c372db6f553"},"outputs":[{"name":"stdout","output_type":"stream","text":["[(0, '0.068*\"driving\" + 0.068*\"pressure\" + 0.068*\"stress\" + 0.068*\"cause\"'), (1, '0.052*\"write\" + 0.052*\"shop\" + 0.052*\"story\" + 0.052*\"coffee\"'), (2, '0.068*\"driving\" + 0.068*\"lot\" + 0.068*\"practice\" + 0.068*\"bill\"')]\n"]}],"source":["print(ldamodel.print_topics(num_topics=3, num_words=4))\n"]},{"cell_type":"markdown","id":"0ce85775","metadata":{"id":"0ce85775"},"source":["# Aspect Mining"]},{"cell_type":"code","execution_count":null,"id":"e1e11399","metadata":{"id":"e1e11399"},"outputs":[],"source":["import stanza\n","#stanza.download('en')\n"]},{"cell_type":"code","execution_count":null,"id":"473a79d6","metadata":{"id":"473a79d6","outputId":"cb2556b5-0528-4ebc-a840-43e74b874286"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to\n","[nltk_data]     C:\\Users\\prati\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to\n","[nltk_data]     C:\\Users\\prati\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     C:\\Users\\prati\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n"]},{"data":{"text/plain":["True"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["nltk.download('stopwords')\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n"]},{"cell_type":"code","execution_count":null,"id":"0e7e0685","metadata":{"id":"0e7e0685"},"outputs":[],"source":["#!pip install stanfordnlp\n","import pandas as pd\n","import numpy as np\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.corpus import wordnet\n","from nltk.tokenize import word_tokenize, sent_tokenize\n","from nltk.stem.wordnet import WordNetLemmatizer \n","import stanfordnlp"]},{"cell_type":"code","execution_count":null,"id":"f3012ad9","metadata":{"id":"f3012ad9"},"outputs":[],"source":["txt = \"Battery life is ok, camera is bad but The Sound Quality is great.\""]},{"cell_type":"code","execution_count":null,"id":"026f115f","metadata":{"id":"026f115f"},"outputs":[],"source":["txt = txt.lower()\n","sentList = nltk.sent_tokenize(txt)"]},{"cell_type":"code","execution_count":null,"id":"9d8161c2","metadata":{"id":"9d8161c2","outputId":"2edb8957-8b37-468c-8a97-dc3c895063c1"},"outputs":[{"name":"stdout","output_type":"stream","text":["[('battery', 'NN'), ('life', 'NN'), ('is', 'VBZ'), ('ok', 'JJ'), (',', ','), ('camera', 'NN'), ('is', 'VBZ'), ('bad', 'JJ'), ('but', 'CC'), ('the', 'DT'), ('sound', 'JJ'), ('quality', 'NN'), ('is', 'VBZ'), ('great', 'JJ'), ('.', '.')]\n"]}],"source":["for line in sentList:\n","    txt_list = nltk.word_tokenize(line)\n","    taggedList = nltk.pos_tag(txt_list)\n","print(taggedList)"]},{"cell_type":"code","execution_count":null,"id":"612cd533","metadata":{"id":"612cd533","outputId":"1b3c6ae0-1392-4488-941a-5ffb2e2a4c49"},"outputs":[{"name":"stdout","output_type":"stream","text":["batterylife is ok , camera is bad but the sound quality is great .\n"]}],"source":["newwordList = []\n","flag = 0\n","for i in range(0,len(taggedList)-1):\n","    if(taggedList[i][1]==\"NN\" and taggedList[i+1][1]==\"NN\"):\n","        newwordList.append(taggedList[i][0]+taggedList[i+1][0])\n","        flag=1\n","    else:\n","        if(flag==1):\n","            flag=0\n","            continue\n","        newwordList.append(taggedList[i][0])\n","        if(i==len(taggedList)-2):\n","            newwordList.append(taggedList[i+1][0])\n","finaltxt = ' '.join(word for word in newwordList)\n","print(finaltxt)"]},{"cell_type":"code","execution_count":null,"id":"7524187c","metadata":{"id":"7524187c"},"outputs":[],"source":["stop_words = set(stopwords.words('english'))\n","new_txt_list = nltk.word_tokenize(finaltxt)\n","wordsList = [w for w in new_txt_list if not w in stop_words]\n","taggedList = nltk.pos_tag(wordsList)"]},{"cell_type":"code","execution_count":null,"id":"96aefaf6","metadata":{"id":"96aefaf6","outputId":"d5148522-4a5d-4d25-fbe0-3426f751f2b6","colab":{"referenced_widgets":["6b2a6622a4aa4d3cb558e4ce5450a7aa"]}},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-11-22 01:35:44 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6b2a6622a4aa4d3cb558e4ce5450a7aa","version_major":2,"version_minor":0},"text/plain":["Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.1.json:   0%|   â€¦"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["2022-11-22 01:35:47 INFO: Loading these models for language: en (English):\n","============================\n","| Processor    | Package   |\n","----------------------------\n","| tokenize     | combined  |\n","| pos          | combined  |\n","| lemma        | combined  |\n","| depparse     | combined  |\n","| sentiment    | sstplus   |\n","| constituency | wsj       |\n","| ner          | ontonotes |\n","============================\n","\n","2022-11-22 01:35:47 INFO: Use device: cpu\n","2022-11-22 01:35:47 INFO: Loading: tokenize\n","2022-11-22 01:35:48 INFO: Loading: pos\n","2022-11-22 01:35:48 INFO: Loading: lemma\n","2022-11-22 01:35:48 INFO: Loading: depparse\n","2022-11-22 01:35:49 INFO: Loading: sentiment\n","2022-11-22 01:35:50 INFO: Loading: constituency\n","2022-11-22 01:35:51 INFO: Loading: ner\n","2022-11-22 01:35:53 INFO: Done loading processors!\n"]},{"name":"stdout","output_type":"stream","text":["[['batterylife', 'ok', 'nsubj'], ['is', 'ok', 'cop'], ['ok', 0, 'root'], [',', 'ok', 'punct'], ['camera', 'bad', 'nsubj'], ['is', 'bad', 'cop'], ['bad', 'ok', 'conj'], ['but', 'great', 'cc'], ['the', 'quality', 'det'], ['sound', 'quality', 'compound'], ['quality', 'great', 'nsubj'], ['is', 'great', 'cop'], ['great', 'ok', 'conj'], ['.', 'ok', 'punct']]\n"]}],"source":["nlp = stanza.Pipeline()\n","doc = nlp(finaltxt)\n","dep_node = []\n","for dep_edge in doc.sentences[0].dependencies:\n","    dep_node.append([dep_edge[2].text, dep_edge[0].id, dep_edge[1]])\n","for i in range(0, len(dep_node)):\n","    if(int(dep_node[i][1]) != 0):\n","        dep_node[i][1] = newwordList[(int(dep_node[i][1]) - 1)]\n","print(dep_node)"]},{"cell_type":"code","execution_count":null,"id":"599607f1","metadata":{"id":"599607f1","outputId":"74160065-de05-488f-9891-5010277da459"},"outputs":[{"name":"stdout","output_type":"stream","text":["[['batterylife', 'NN'], ['ok', 'NN'], ['camera', 'NN'], ['bad', 'JJ'], ['sound', 'JJ'], ['quality', 'NN'], ['great', 'JJ']]\n","['batterylife', 'ok', 'camera', 'bad', 'sound', 'quality', 'great']\n"]}],"source":["featureList = []\n","categories = []\n","totalfeatureList = []\n","for i in taggedList:\n","    if(i[1]=='JJ' or i[1]=='NN' or i[1]=='JJR' or i[1]=='NNS' or i[1]=='RB'):\n","        featureList.append(list(i))\n","        totalfeatureList.append(list(i)) # stores all the features for every sentence\n","        categories.append(i[0])\n","print(featureList)\n","print(categories)"]},{"cell_type":"code","execution_count":null,"id":"0d0f1dbc","metadata":{"id":"0d0f1dbc","outputId":"600ae93d-e7a9-4177-df66-64687a227764"},"outputs":[{"name":"stdout","output_type":"stream","text":["[['batterylife', ['ok']], ['ok', ['batterylife']], ['camera', ['bad']], ['bad', ['camera']], ['sound', ['quality']], ['quality', ['sound', 'great']], ['great', ['quality']]]\n"]}],"source":["fcluster = []\n","for i in featureList:\n","    filist = []\n","    for j in dep_node:\n","        if((j[0]==i[0] or j[1]==i[0]) and (j[2] in [\"nsubj\", \"acl:relcl\", \"obj\", \"dobj\", \"agent\", \"advmod\", \"amod\", \"neg\", \"prep_of\", \"acomp\", \"xcomp\", \"compound\"])):\n","            if(j[0]==i[0]):\n","                filist.append(j[1])\n","            else:\n","                filist.append(j[0])\n","    fcluster.append([i[0], filist])\n","print(fcluster)"]},{"cell_type":"code","execution_count":null,"id":"db00ffb0","metadata":{"id":"db00ffb0","outputId":"8201fbfa-677b-4364-f047-897e07fe18ef"},"outputs":[{"name":"stdout","output_type":"stream","text":["[['batterylife', ['ok']], ['ok', ['batterylife']], ['camera', ['bad']], ['quality', ['sound', 'great']]]\n"]}],"source":["finalcluster = []\n","dic = {}\n","for i in featureList:\n","    dic[i[0]] = i[1]\n","for i in fcluster:\n","    if(dic[i[0]]=='NN'):\n","        finalcluster.append(i)\n","print(finalcluster)"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"vscode":{"interpreter":{"hash":"255e1c9af8ca143710c9fb834bd30e7186aec95d3cf3a6cf871f18d5ccb54e37"}},"colab":{"provenance":[{"file_id":"1ukmHI6YNkB6Fj440qn5OCVf8wl8IULql","timestamp":1669917667209}]}},"nbformat":4,"nbformat_minor":5}